# Adversarial Patch

题目是对抗补丁，通过浏览全文，我觉得对抗补丁的含义就是通过在图像上加一个色彩明亮的区域（这么说我觉得还是太普通了，用Patch感觉还是好一点），提取特征的时候占据一个最重要的特征，对分类器造成了误差。

深度学习系统很容易受到对抗的例子。

对抗性的例子很容易拓展到现实世界。文中论述，即使在不同的光照和方向上会出现这种情况；对抗性的物体也可以3D打印出，不过在不同的方向和尺寸上还是错误的分类

文中论述的对抗性的补丁利用它能产生比其他目标更显著的特征，造成了对目标检测器和模型的性能，但是我们希望能够输出这个补丁的分类结果，但是不要影响图像的其他物体。